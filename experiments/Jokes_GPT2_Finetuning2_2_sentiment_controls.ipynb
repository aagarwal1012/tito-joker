{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jokes_GPT2_Finetuning2_2_sentiment_controls.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJtGGTRs1g2WOGB5f5yyUE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f56c716e8cb34130a39b58df30e2aeb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_346fe1bba6ad4e229989241854a8c99f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c6b0ae29ac51447a996108b1ddc745e1",
              "IPY_MODEL_e863b6a382e342e982b4d3596d5cce69"
            ]
          }
        },
        "346fe1bba6ad4e229989241854a8c99f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6b0ae29ac51447a996108b1ddc745e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3f751e4ef84d4d77950452a2db13b677",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 230,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 230,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63e7b5fb20d844168848f86d027800ec"
          }
        },
        "e863b6a382e342e982b4d3596d5cce69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b0684cca35344d5691dfca28c5186b6a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230/230 [00:00&lt;00:00, 381B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96ac84a02454460f89df1b6d4c0e5868"
          }
        },
        "3f751e4ef84d4d77950452a2db13b677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63e7b5fb20d844168848f86d027800ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0684cca35344d5691dfca28c5186b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "96ac84a02454460f89df1b6d4c0e5868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66a8d6ad150047838c4f168d329d91b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8adabf6ff09a4fd1a4531cb727f9aa41",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8fea8ea771b84598883bfe56c9983568",
              "IPY_MODEL_91f66713021c4da9bc48033cf4b2549e"
            ]
          }
        },
        "8adabf6ff09a4fd1a4531cb727f9aa41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8fea8ea771b84598883bfe56c9983568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d4ea6a601ca049ef96577b02393d1997",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb538b9d0bd74f7e8773c4261c2caccb"
          }
        },
        "91f66713021c4da9bc48033cf4b2549e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb7a10908c374f1c91174464551383fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:01&lt;00:00, 618kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4ef910d7a254375b2f6836b6dfed220"
          }
        },
        "d4ea6a601ca049ef96577b02393d1997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb538b9d0bd74f7e8773c4261c2caccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb7a10908c374f1c91174464551383fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4ef910d7a254375b2f6836b6dfed220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44268d8feb9043b9883d8d1a21222bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd659c2860a84c74a1f30d2e031058fb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69dbb4d7420c46c98609428aa6c14009",
              "IPY_MODEL_6111df32c13746629cb127c084cb288d"
            ]
          }
        },
        "bd659c2860a84c74a1f30d2e031058fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69dbb4d7420c46c98609428aa6c14009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_78ff1dd0b09f4dafb28c5a610b3e3a50",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d529758637c4d5b9d91db244e9251df"
          }
        },
        "6111df32c13746629cb127c084cb288d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ecfb48304fe4f17b51427d63ae60971",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.05MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_939a52efbd3a4bbf86a70dc43c99b968"
          }
        },
        "78ff1dd0b09f4dafb28c5a610b3e3a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d529758637c4d5b9d91db244e9251df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ecfb48304fe4f17b51427d63ae60971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "939a52efbd3a4bbf86a70dc43c99b968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enzoampil/tito-joker/blob/master/experiments/Jokes_GPT2_Finetuning2_2_sentiment_controls.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9KYxtT8I2jC",
        "colab_type": "text"
      },
      "source": [
        "# Tito Joker v2.2\n",
        "\n",
        "## Updates:\n",
        "1. Sentiment will be infused into the jokes dataset w/ a special sentiment token\n",
        "3. Sentiment controls to be added to the webapp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnfIHs24ayKK",
        "colab_type": "text"
      },
      "source": [
        "## Note that the experiment notebooks have ending numbers corresponding to the model's number (this is model2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLDVNvwt-JIp",
        "colab_type": "code",
        "outputId": "b368a802-db75-4dee-8b0e-7c5d6cb04abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 4.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 5.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 5.0MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 4.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 5.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 5.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\r\u001b[K     |▍                               | 10kB 22.6MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 17.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 22.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 20.3MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 17.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 19.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 14.7MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 16.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 15.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 102kB 15.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112kB 15.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 122kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 143kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 153kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 174kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 184kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 194kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 204kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 215kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 225kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 235kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 245kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 256kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 266kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 276kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 286kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 296kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 307kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 317kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 327kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 337kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 348kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 358kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 368kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 378kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 389kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 399kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 409kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 419kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 430kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 440kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 450kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 460kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 471kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 481kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 491kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 501kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 512kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 522kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 532kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 542kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 552kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 563kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 573kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 583kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 593kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 604kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 614kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 624kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 634kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 645kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 655kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 665kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 675kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 686kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 696kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 706kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 716kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 727kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 737kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 747kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 757kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 768kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 778kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 788kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 798kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 808kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 819kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 829kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 839kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 849kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 860kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 870kB 15.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.35)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 14.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 35.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.35 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.35)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.35->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.35->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=405e5d147d40782da6c7342337e936c861a4a39de06e2517f97a97789707846f\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA3L_xtuOECl",
        "colab_type": "code",
        "outputId": "aa20f32c-5825-4c28-e329-1fe3a4a470da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/75)\u001b[K\rremote: Counting objects:   2% (2/75)\u001b[K\rremote: Counting objects:   4% (3/75)\u001b[K\rremote: Counting objects:   5% (4/75)\u001b[K\rremote: Counting objects:   6% (5/75)\u001b[K\rremote: Counting objects:   8% (6/75)\u001b[K\rremote: Counting objects:   9% (7/75)\u001b[K\rremote: Counting objects:  10% (8/75)\u001b[K\rremote: Counting objects:  12% (9/75)\u001b[K\rremote: Counting objects:  13% (10/75)\u001b[K\rremote: Counting objects:  14% (11/75)\u001b[K\rremote: Counting objects:  16% (12/75)\u001b[K\rremote: Counting objects:  17% (13/75)\u001b[K\rremote: Counting objects:  18% (14/75)\u001b[K\rremote: Counting objects:  20% (15/75)\u001b[K\rremote: Counting objects:  21% (16/75)\u001b[K\rremote: Counting objects:  22% (17/75)\u001b[K\rremote: Counting objects:  24% (18/75)\u001b[K\rremote: Counting objects:  25% (19/75)\u001b[K\rremote: Counting objects:  26% (20/75)\u001b[K\rremote: Counting objects:  28% (21/75)\u001b[K\rremote: Counting objects:  29% (22/75)\u001b[K\rremote: Counting objects:  30% (23/75)\u001b[K\rremote: Counting objects:  32% (24/75)\u001b[K\rremote: Counting objects:  33% (25/75)\u001b[K\rremote: Counting objects:  34% (26/75)\u001b[K\rremote: Counting objects:  36% (27/75)\u001b[K\rremote: Counting objects:  37% (28/75)\u001b[K\rremote: Counting objects:  38% (29/75)\u001b[K\rremote: Counting objects:  40% (30/75)\u001b[K\rremote: Counting objects:  41% (31/75)\u001b[K\rremote: Counting objects:  42% (32/75)\u001b[K\rremote: Counting objects:  44% (33/75)\u001b[K\rremote: Counting objects:  45% (34/75)\u001b[K\rremote: Counting objects:  46% (35/75)\u001b[K\rremote: Counting objects:  48% (36/75)\u001b[K\rremote: Counting objects:  49% (37/75)\u001b[K\rremote: Counting objects:  50% (38/75)\u001b[K\rremote: Counting objects:  52% (39/75)\u001b[K\rremote: Counting objects:  53% (40/75)\u001b[K\rremote: Counting objects:  54% (41/75)\u001b[K\rremote: Counting objects:  56% (42/75)\u001b[K\rremote: Counting objects:  57% (43/75)\u001b[K\rremote: Counting objects:  58% (44/75)\u001b[K\rremote: Counting objects:  60% (45/75)\u001b[K\rremote: Counting objects:  61% (46/75)\u001b[K\rremote: Counting objects:  62% (47/75)\u001b[K\rremote: Counting objects:  64% (48/75)\u001b[K\rremote: Counting objects:  65% (49/75)\u001b[K\rremote: Counting objects:  66% (50/75)\u001b[K\rremote: Counting objects:  68% (51/75)\u001b[K\rremote: Counting objects:  69% (52/75)\u001b[K\rremote: Counting objects:  70% (53/75)\u001b[K\rremote: Counting objects:  72% (54/75)\u001b[K\rremote: Counting objects:  73% (55/75)\u001b[K\rremote: Counting objects:  74% (56/75)\u001b[K\rremote: Counting objects:  76% (57/75)\u001b[K\rremote: Counting objects:  77% (58/75)\u001b[K\rremote: Counting objects:  78% (59/75)\u001b[K\rremote: Counting objects:  80% (60/75)\u001b[K\rremote: Counting objects:  81% (61/75)\u001b[K\rremote: Counting objects:  82% (62/75)\u001b[K\rremote: Counting objects:  84% (63/75)\u001b[K\rremote: Counting objects:  85% (64/75)\u001b[K\rremote: Counting objects:  86% (65/75)\u001b[K\rremote: Counting objects:  88% (66/75)\u001b[K\rremote: Counting objects:  89% (67/75)\u001b[K\rremote: Counting objects:  90% (68/75)\u001b[K\rremote: Counting objects:  92% (69/75)\u001b[K\rremote: Counting objects:  93% (70/75)\u001b[K\rremote: Counting objects:  94% (71/75)\u001b[K\rremote: Counting objects:  96% (72/75)\u001b[K\rremote: Counting objects:  97% (73/75)\u001b[K\rremote: Counting objects:  98% (74/75)\u001b[K\rremote: Counting objects: 100% (75/75)\u001b[K\rremote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 23645 (delta 34), reused 34 (delta 16), pack-reused 23570\u001b[K\n",
            "Receiving objects: 100% (23645/23645), 14.20 MiB | 13.69 MiB/s, done.\n",
            "Resolving deltas: 100% (16729/16729), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-0f7ISuzMBL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoHOafNoTwg1",
        "colab_type": "code",
        "outputId": "a2b5abc6-0833-4b38-a1dc-675fbe92cc5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/enzoampil/tito-joker.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tito-joker'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/154)\u001b[K\rremote: Counting objects:   1% (2/154)\u001b[K\rremote: Counting objects:   2% (4/154)\u001b[K\rremote: Counting objects:   3% (5/154)\u001b[K\rremote: Counting objects:   4% (7/154)\u001b[K\rremote: Counting objects:   5% (8/154)\u001b[K\rremote: Counting objects:   6% (10/154)\u001b[K\rremote: Counting objects:   7% (11/154)\u001b[K\rremote: Counting objects:   8% (13/154)\u001b[K\rremote: Counting objects:   9% (14/154)\u001b[K\rremote: Counting objects:  10% (16/154)\u001b[K\rremote: Counting objects:  11% (17/154)\u001b[K\rremote: Counting objects:  12% (19/154)\u001b[K\rremote: Counting objects:  13% (21/154)\u001b[K\rremote: Counting objects:  14% (22/154)\u001b[K\rremote: Counting objects:  15% (24/154)\u001b[K\rremote: Counting objects:  16% (25/154)\u001b[K\rremote: Counting objects:  17% (27/154)\u001b[K\rremote: Counting objects:  18% (28/154)\u001b[K\rremote: Counting objects:  19% (30/154)\u001b[K\rremote: Counting objects:  20% (31/154)\u001b[K\rremote: Counting objects:  21% (33/154)\u001b[K\rremote: Counting objects:  22% (34/154)\u001b[K\rremote: Counting objects:  23% (36/154)\u001b[K\rremote: Counting objects:  24% (37/154)\u001b[K\rremote: Counting objects:  25% (39/154)\u001b[K\rremote: Counting objects:  26% (41/154)\u001b[K\rremote: Counting objects:  27% (42/154)\u001b[K\rremote: Counting objects:  28% (44/154)\u001b[K\rremote: Counting objects:  29% (45/154)\u001b[K\rremote: Counting objects:  30% (47/154)\u001b[K\rremote: Counting objects:  31% (48/154)\u001b[K\rremote: Counting objects:  32% (50/154)\u001b[K\rremote: Counting objects:  33% (51/154)\u001b[K\rremote: Counting objects:  34% (53/154)\u001b[K\rremote: Counting objects:  35% (54/154)\u001b[K\rremote: Counting objects:  36% (56/154)\u001b[K\rremote: Counting objects:  37% (57/154)\u001b[K\rremote: Counting objects:  38% (59/154)\u001b[K\rremote: Counting objects:  39% (61/154)\u001b[K\rremote: Counting objects:  40% (62/154)\u001b[K\rremote: Counting objects:  41% (64/154)\u001b[K\rremote: Counting objects:  42% (65/154)\u001b[K\rremote: Counting objects:  43% (67/154)\u001b[K\rremote: Counting objects:  44% (68/154)\u001b[K\rremote: Counting objects:  45% (70/154)\u001b[K\rremote: Counting objects:  46% (71/154)\u001b[K\rremote: Counting objects:  47% (73/154)\u001b[K\rremote: Counting objects:  48% (74/154)\u001b[K\rremote: Counting objects:  49% (76/154)\u001b[K\rremote: Counting objects:  50% (77/154)\u001b[K\rremote: Counting objects:  51% (79/154)\u001b[K\rremote: Counting objects:  52% (81/154)\u001b[K\rremote: Counting objects:  53% (82/154)\u001b[K\rremote: Counting objects:  54% (84/154)\u001b[K\rremote: Counting objects:  55% (85/154)\u001b[K\rremote: Counting objects:  56% (87/154)\u001b[K\rremote: Counting objects:  57% (88/154)\u001b[K\rremote: Counting objects:  58% (90/154)\u001b[K\rremote: Counting objects:  59% (91/154)\u001b[K\rremote: Counting objects:  60% (93/154)\u001b[K\rremote: Counting objects:  61% (94/154)\u001b[K\rremote: Counting objects:  62% (96/154)\u001b[K\rremote: Counting objects:  63% (98/154)\u001b[K\rremote: Counting objects:  64% (99/154)\u001b[K\rremote: Counting objects:  65% (101/154)\u001b[K\rremote: Counting objects:  66% (102/154)\u001b[K\rremote: Counting objects:  67% (104/154)\u001b[K\rremote: Counting objects:  68% (105/154)\u001b[K\rremote: Counting objects:  69% (107/154)\u001b[K\rremote: Counting objects:  70% (108/154)\u001b[K\rremote: Counting objects:  71% (110/154)\u001b[K\rremote: Counting objects:  72% (111/154)\u001b[K\rremote: Counting objects:  73% (113/154)\u001b[K\rremote: Counting objects:  74% (114/154)\u001b[K\rremote: Counting objects:  75% (116/154)\u001b[K\rremote: Counting objects:  76% (118/154)\u001b[K\rremote: Counting objects:  77% (119/154)\u001b[K\rremote: Counting objects:  78% (121/154)\u001b[K\rremote: Counting objects:  79% (122/154)\u001b[K\rremote: Counting objects:  80% (124/154)\u001b[K\rremote: Counting objects:  81% (125/154)\u001b[K\rremote: Counting objects:  82% (127/154)\u001b[K\rremote: Counting objects:  83% (128/154)\u001b[K\rremote: Counting objects:  84% (130/154)\u001b[K\rremote: Counting objects:  85% (131/154)\u001b[K\rremote: Counting objects:  86% (133/154)\u001b[K\rremote: Counting objects:  87% (134/154)\u001b[K\rremote: Counting objects:  88% (136/154)\u001b[K\rremote: Counting objects:  89% (138/154)\u001b[K\rremote: Counting objects:  90% (139/154)\u001b[K\rremote: Counting objects:  91% (141/154)\u001b[K\rremote: Counting objects:  92% (142/154)\u001b[K\rremote: Counting objects:  93% (144/154)\u001b[K\rremote: Counting objects:  94% (145/154)\u001b[K\rremote: Counting objects:  95% (147/154)\u001b[K\rremote: Counting objects:  96% (148/154)\u001b[K\rremote: Counting objects:  97% (150/154)\u001b[K\rremote: Counting objects:  98% (151/154)\u001b[K\rremote: Counting objects:  99% (153/154)\u001b[K\rremote: Counting objects: 100% (154/154)\u001b[K\rremote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
            "remote: Total 507 (delta 85), reused 130 (delta 67), pack-reused 353\u001b[K\n",
            "Receiving objects: 100% (507/507), 6.13 MiB | 9.33 MiB/s, done.\n",
            "Resolving deltas: 100% (281/281), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN52JojWT-il",
        "colab_type": "text"
      },
      "source": [
        "## Download raw jokes dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIN_XvESR-yn",
        "colab_type": "code",
        "outputId": "c9d5e6c8-a518-4e8c-a5a3-68e499edc365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/joke-generator-model1/short-jokes.zip && unzip short-jokes.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-09 09:12:50--  https://storage.googleapis.com/joke-generator-model1/short-jokes.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.126.128, 2a00:1450:4013:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.126.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10679873 (10M) [application/zip]\n",
            "Saving to: ‘short-jokes.zip’\n",
            "\n",
            "\rshort-jokes.zip       0%[                    ]       0  --.-KB/s               \rshort-jokes.zip      39%[======>             ]   4.01M  14.1MB/s               \rshort-jokes.zip     100%[===================>]  10.18M  33.9MB/s    in 0.3s    \n",
            "\n",
            "2020-04-09 09:12:51 (33.9 MB/s) - ‘short-jokes.zip’ saved [10679873/10679873]\n",
            "\n",
            "Archive:  short-jokes.zip\n",
            "  inflating: shortjokes.csv          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlijSmwXbgxo",
        "colab_type": "text"
      },
      "source": [
        "## Process the raw jokes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIlbpgTwPor1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RjTzT6RfrBW",
        "colab_type": "code",
        "outputId": "3b6fa70c-720a-4a5a-ae63-bb289d9d8f81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd tito-joker"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tito-joker\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWRtNP5we0_S",
        "colab_type": "text"
      },
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkSvjCmVSJQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Won't run this first since sentiment analysis isn't applied here yet\n",
        "#!python ./src/utils/process_jokes.py ../shortjokes.csv ./data/riddle_jokes.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2x8UPOJqiue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_jokes(raw_fp):\n",
        "    \"\"\"\n",
        "    Returns jokes dataframe w/ no special tokens yet.\n",
        "    \n",
        "    This makes sense in this context since we're using a pretrained sentiment analysis model which doesn't recognize our new joke speciic tokens.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(raw_fp)\n",
        "\n",
        "    # Append token at the end of each joke to indicate the end of a joke\n",
        "\n",
        "    what_jokes = df[df.Joke.str.lower().str.startswith(\"what\")].Joke.str.split(\"?\")\n",
        "    how_jokes = df[df.Joke.str.lower().str.startswith(\"how\")].Joke.str.split(\"?\")\n",
        "    why_jokes = df[df.Joke.str.lower().str.startswith(\"why\")].Joke.str.split(\"?\")\n",
        "    when_jokes = df[df.Joke.str.lower().str.startswith(\"when\")].Joke.str.split(\"?\")\n",
        "    where_jokes = df[df.Joke.str.lower().str.startswith(\"where\")].Joke.str.split(\"?\")\n",
        "\n",
        "    jokes = []\n",
        "    for joke_ in [what_jokes, how_jokes, why_jokes, when_jokes, where_jokes]:\n",
        "        joke_df_ = pd.DataFrame(joke_.values.tolist()).iloc[:, :2].dropna()\n",
        "        joke_df_.columns = [\"question\", \"answer\"]\n",
        "        jokes.append(joke_df_)\n",
        "\n",
        "    jokes_df = pd.concat(jokes)\n",
        "    jokes_df = (\n",
        "        jokes_df[~(jokes_df.answer.isin([\"\"]))].drop_duplicates().reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    return jokes_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB4P7SwOPeC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jokes_df = process_jokes('../shortjokes.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgHpSankTYe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jokes_df['question_answer'] = (jokes_df.question + \"? \" + jokes_df.answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJnJNj19PvzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "c9008009-03e7-4b08-88d6-27cc690c802a"
      },
      "source": [
        "jokes_df"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>question_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What do you do if a bird shits on your car</td>\n",
              "      <td>Don't ask her out again.</td>\n",
              "      <td>What do you do if a bird shits on your car?  D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What should you do before criticizing Pac-Man</td>\n",
              "      <td>WAKA WAKA WAKA mile in his shoes</td>\n",
              "      <td>What should you do before criticizing Pac-Man?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What's the difference between an illegal Mexic...</td>\n",
              "      <td>Nothing... they were both made to steal Ameri...</td>\n",
              "      <td>What's the difference between an illegal Mexic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What do you call a barbarian you can't see</td>\n",
              "      <td>an Invisigoth.</td>\n",
              "      <td>What do you call a barbarian you can't see?  a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What did Arnold Schwarzenegger say at the abor...</td>\n",
              "      <td>Hasta last vista, baby.</td>\n",
              "      <td>What did Arnold Schwarzenegger say at the abor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66638</th>\n",
              "      <td>Where does dubious pasta come from</td>\n",
              "      <td>The spaghetto. I can't take all the credit, h...</td>\n",
              "      <td>Where does dubious pasta come from?  The spagh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66639</th>\n",
              "      <td>Where does the midget pizza chef with epilepsy...</td>\n",
              "      <td>Little seizures</td>\n",
              "      <td>Where does the midget pizza chef with epilepsy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66640</th>\n",
              "      <td>Where do you hide an airport</td>\n",
              "      <td>IN PLANE SIGHT!</td>\n",
              "      <td>Where do you hide an airport?  IN PLANE SIGHT!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66641</th>\n",
              "      <td>Where did L Ron Hubbard store his dishes</td>\n",
              "      <td>In the L Ron cupboard.</td>\n",
              "      <td>Where did L Ron Hubbard store his dishes?  In ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66642</th>\n",
              "      <td>Where do volcanoes go to relieve themselves</td>\n",
              "      <td>The lavatory, of course!</td>\n",
              "      <td>Where do volcanoes go to relieve themselves?  ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>66643 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                question  ...                                    question_answer\n",
              "0             What do you do if a bird shits on your car  ...  What do you do if a bird shits on your car?  D...\n",
              "1          What should you do before criticizing Pac-Man  ...  What should you do before criticizing Pac-Man?...\n",
              "2      What's the difference between an illegal Mexic...  ...  What's the difference between an illegal Mexic...\n",
              "3             What do you call a barbarian you can't see  ...  What do you call a barbarian you can't see?  a...\n",
              "4      What did Arnold Schwarzenegger say at the abor...  ...  What did Arnold Schwarzenegger say at the abor...\n",
              "...                                                  ...  ...                                                ...\n",
              "66638                 Where does dubious pasta come from  ...  Where does dubious pasta come from?  The spagh...\n",
              "66639  Where does the midget pizza chef with epilepsy...  ...  Where does the midget pizza chef with epilepsy...\n",
              "66640                       Where do you hide an airport  ...     Where do you hide an airport?  IN PLANE SIGHT!\n",
              "66641           Where did L Ron Hubbard store his dishes  ...  Where did L Ron Hubbard store his dishes?  In ...\n",
              "66642        Where do volcanoes go to relieve themselves  ...  Where do volcanoes go to relieve themselves?  ...\n",
              "\n",
              "[66643 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXuO5Vv6Nz0R",
        "colab_type": "text"
      },
      "source": [
        "# Run sentiment analysis on the jokes\n",
        "\n",
        "## There are 3 approaches we can take in scoring sentiment\n",
        "1. **Score both question and answer**\n",
        "2. Score only the question\n",
        "3. **Score only the answer**\n",
        "\n",
        "*Since in Tito Joker's question, we expect users to ask the question, I believe it makes more sense to score the answer specifically. However, I also think that answers are quite short and may not give enough context. To be safe, I will apply both 1 and 3.*\n",
        "\n",
        "I also realized just now that 1 will be the easiest to implement as a special token, since we can just play the tag right after the CLS token. For 3, it will be harder if we want to add the token after the question at inference. It's definitely doable but we will have to run experiments.\n",
        "\n",
        "With the answer only implementation, I might still just put the token at the beginning of the model. The problem is that the question will also be dependendt on the sentiment tag, but this becomes less of an issue as long as people actually ask questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMxduNgVN3BL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
        "from tqdm import tqdm\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CbIi1nnU9A9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d37ec611-04b2-4029-f67c-54ab6116dfa1"
      },
      "source": [
        "import torch\n",
        "torch.cuda.current_device()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Deo7uUNqN3Gp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "f56c716e8cb34130a39b58df30e2aeb2",
            "346fe1bba6ad4e229989241854a8c99f",
            "c6b0ae29ac51447a996108b1ddc745e1",
            "e863b6a382e342e982b4d3596d5cce69",
            "3f751e4ef84d4d77950452a2db13b677",
            "63e7b5fb20d844168848f86d027800ec",
            "b0684cca35344d5691dfca28c5186b6a",
            "96ac84a02454460f89df1b6d4c0e5868"
          ]
        },
        "outputId": "769fb58c-06af-41c4-a950-f77e5d04adb2"
      },
      "source": [
        "nlp = pipeline('sentiment-analysis', device=0)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f56c716e8cb34130a39b58df30e2aeb2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=230, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQlANj3XN3JE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d91e7c8b-e4d9-4573-f340-67ba4adfa6ef"
      },
      "source": [
        "#Test\n",
        "nlp(\"I am very glad to be here\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9996952}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge7XV78pN3K7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer_sentiment = [nlp(ans) for ans in jokes_df.answer.values[:20]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5tCil8oRnJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "7eb433ab-f356-4554-fc47-449e3efea3ba"
      },
      "source": [
        "# The results look mixed. The long answers seem to have accurate answers, but the one word answers don't seem right\n",
        "for i in range(20):\n",
        "    print(answer_sentiment[i], jokes_df.answer.values[i])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'label': 'NEGATIVE', 'score': 0.98510593}]  Don't ask her out again.\n",
            "[{'label': 'POSITIVE', 'score': 0.93220097}]  WAKA WAKA WAKA mile in his shoes\n",
            "[{'label': 'NEGATIVE', 'score': 0.9994851}]  Nothing... they were both made to steal American jobs.\n",
            "[{'label': 'POSITIVE', 'score': 0.77296317}]  an Invisigoth.\n",
            "[{'label': 'POSITIVE', 'score': 0.9947985}]  Hasta last vista, baby.\n",
            "[{'label': 'POSITIVE', 'score': 0.61819375}]  Spudnik\n",
            "[{'label': 'POSITIVE', 'score': 0.99789554}]  Reserection\n",
            "[{'label': 'POSITIVE', 'score': 0.99252135}]  The New York jets.\n",
            "[{'label': 'POSITIVE', 'score': 0.9998734}]  One's a Goodyear, an the other's a great year.\n",
            "[{'label': 'NEGATIVE', 'score': 0.99524903}]  When you dump your load in a washer, it doesn't follow you around for a week.\n",
            "[{'label': 'POSITIVE', 'score': 0.99945635}]  Stevie Wonder\n",
            "[{'label': 'NEGATIVE', 'score': 0.9496889}]  I've been through a lot.\n",
            "[{'label': 'POSITIVE', 'score': 0.9976123}]  Make sure to come upstairs.\n",
            "[{'label': 'NEGATIVE', 'score': 0.97490466}]  If you incest.\n",
            "[{'label': 'POSITIVE', 'score': 0.98913103}]  \"Depends\"\n",
            "[{'label': 'NEGATIVE', 'score': 0.99943906}]  They're both old.\n",
            "[{'label': 'NEGATIVE', 'score': 0.99640864}]  A do-think-he-saurus :) !! Lol What do you call a blind dinosaurs dog\n",
            "[{'label': 'NEGATIVE', 'score': 0.9993615}]  Pregnant (Told to me by one of the kids at work)\n",
            "[{'label': 'NEGATIVE', 'score': 0.99839586}]  Nothing, they're both stuck-up cunts.\n",
            "[{'label': 'POSITIVE', 'score': 0.9990101}]  A hip-hop hip op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpjvNXpKSQfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question_sentiment = [nlp(ans) for ans in jokes_df.question.values[:20]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7QQlaoGSYWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "48c726c4-fac6-4ccc-d74e-4861e1b7fab3"
      },
      "source": [
        "# I find the results here not so convincing\n",
        "for i in range(20):\n",
        "    print(question_sentiment[i], jokes_df.question.values[i])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'label': 'NEGATIVE', 'score': 0.9979136}] What do you do if a bird shits on your car\n",
            "[{'label': 'POSITIVE', 'score': 0.7655616}] What should you do before criticizing Pac-Man\n",
            "[{'label': 'POSITIVE', 'score': 0.8212372}] What's the difference between an illegal Mexican and an autonomous robot...\n",
            "[{'label': 'NEGATIVE', 'score': 0.94881314}] What do you call a barbarian you can't see\n",
            "[{'label': 'NEGATIVE', 'score': 0.9652808}] What did Arnold Schwarzenegger say at the abortion clinic\n",
            "[{'label': 'NEGATIVE', 'score': 0.9907236}] What do you call a potato in space\n",
            "[{'label': 'NEGATIVE', 'score': 0.99344915}] What happens to a necrophiliac after death\n",
            "[{'label': 'POSITIVE', 'score': 0.99935293}] What's Al-Qaeda's favorite American football team\n",
            "[{'label': 'NEGATIVE', 'score': 0.80405384}] What's the difference between a car tyre, and 365 condoms\n",
            "[{'label': 'POSITIVE', 'score': 0.8771809}] What's the difference between a blonde and a washer\n",
            "[{'label': 'NEGATIVE', 'score': 0.99969804}] What's black, blue and doesn't look too well\n",
            "[{'label': 'NEGATIVE', 'score': 0.9696892}] What did the car said to the valet\n",
            "[{'label': 'NEGATIVE', 'score': 0.99288154}] What did the porn actress say when she opened the door\n",
            "[{'label': 'NEGATIVE', 'score': 0.91150063}] What did the hillbilly say to his sister after she asked him to have sex with her\n",
            "[{'label': 'POSITIVE', 'score': 0.9756238}] What do grandparents smell like\n",
            "[{'label': 'POSITIVE', 'score': 0.99320954}] What do people from the 1930's and /r/news jokes have in common\n",
            "[{'label': 'NEGATIVE', 'score': 0.9959678}] What do you call a blind dinosaur\n",
            "[{'label': 'NEGATIVE', 'score': 0.98954993}] What do you call a three-humped camel\n",
            "[{'label': 'NEGATIVE', 'score': 0.96884155}] What did the two tampons say to each other\n",
            "[{'label': 'NEGATIVE', 'score': 0.88708514}] What do you call Jay-Z having a leg transplant\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpzqKbbBS-lJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question_answer_sentiment = [nlp(ans) for ans in jokes_df.question_answer.values[:20]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfrIdE3zTGn-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "5808c953-eda4-40b3-8d52-fd17c4818687"
      },
      "source": [
        "# This one is sort of in the middle\n",
        "for i in range(20):\n",
        "    print(question_answer_sentiment[i], jokes_df.question_answer.values[i])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'label': 'NEGATIVE', 'score': 0.99840784}] What do you do if a bird shits on your car?  Don't ask her out again.\n",
            "[{'label': 'NEGATIVE', 'score': 0.9913214}] What should you do before criticizing Pac-Man?  WAKA WAKA WAKA mile in his shoes\n",
            "[{'label': 'NEGATIVE', 'score': 0.99952585}] What's the difference between an illegal Mexican and an autonomous robot...?  Nothing... they were both made to steal American jobs.\n",
            "[{'label': 'NEGATIVE', 'score': 0.5165516}] What do you call a barbarian you can't see?  an Invisigoth.\n",
            "[{'label': 'NEGATIVE', 'score': 0.98074615}] What did Arnold Schwarzenegger say at the abortion clinic?  Hasta last vista, baby.\n",
            "[{'label': 'NEGATIVE', 'score': 0.99436504}] What do you call a potato in space?  Spudnik\n",
            "[{'label': 'NEGATIVE', 'score': 0.9864824}] What happens to a necrophiliac after death?  Reserection\n",
            "[{'label': 'NEGATIVE', 'score': 0.8593313}] What's Al-Qaeda's favorite American football team?  The New York jets.\n",
            "[{'label': 'POSITIVE', 'score': 0.9965733}] What's the difference between a car tyre, and 365 condoms?  One's a Goodyear, an the other's a great year.\n",
            "[{'label': 'NEGATIVE', 'score': 0.9975137}] What's the difference between a blonde and a washer?  When you dump your load in a washer, it doesn't follow you around for a week.\n",
            "[{'label': 'NEGATIVE', 'score': 0.9964223}] What's black, blue and doesn't look too well?  Stevie Wonder\n",
            "[{'label': 'NEGATIVE', 'score': 0.9958372}] What did the car said to the valet?  I've been through a lot.\n",
            "[{'label': 'NEGATIVE', 'score': 0.99534786}] What did the porn actress say when she opened the door?  Make sure to come upstairs.\n",
            "[{'label': 'NEGATIVE', 'score': 0.9905055}] What did the hillbilly say to his sister after she asked him to have sex with her?  If you incest.\n",
            "[{'label': 'POSITIVE', 'score': 0.6946253}] What do grandparents smell like?  \"Depends\"\n",
            "[{'label': 'NEGATIVE', 'score': 0.99943477}] What do people from the 1930's and /r/news jokes have in common?  They're both old.\n",
            "[{'label': 'NEGATIVE', 'score': 0.9975213}] What do you call a blind dinosaur?  A do-think-he-saurus :) !! Lol What do you call a blind dinosaurs dog\n",
            "[{'label': 'NEGATIVE', 'score': 0.9991583}] What do you call a three-humped camel?  Pregnant (Told to me by one of the kids at work)\n",
            "[{'label': 'NEGATIVE', 'score': 0.9935606}] What did the two tampons say to each other?  Nothing, they're both stuck-up cunts.\n",
            "[{'label': 'POSITIVE', 'score': 0.5897721}] What do you call Jay-Z having a leg transplant?  A hip-hop hip op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox3DBbYAT-4V",
        "colab_type": "text"
      },
      "source": [
        "My view so far is to go with answer sentiment tagging first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Sbj0s1ATGsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer_sentiment_all = [nlp(ans) for ans in tqdm(jokes_df.answer.values)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgnEcEcBegUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer_sentiment_all_dict = [pred[0] for pred in answer_sentiment_all]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB3LRSr8evS7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b51cc7ae-79e0-447a-ef41-790d45750c01"
      },
      "source": [
        "answer_sentiment_all_dict[0]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 'NEGATIVE', 'score': 0.9851059}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SX7dBU5eHpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer_sentiment_all_df = pd.DataFrame(answer_sentiment_all_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lBYqn8UeRKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6be48afd-3f88-466a-9b3d-e110ba3220ad"
      },
      "source": [
        "answer_sentiment_all_df.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.985106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.932200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.999485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.772967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.994798</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label     score\n",
              "0  NEGATIVE  0.985106\n",
              "1  POSITIVE  0.932200\n",
              "2  NEGATIVE  0.999485\n",
              "3  POSITIVE  0.772967\n",
              "4  POSITIVE  0.994798"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux-Wn8EIezdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jokes_sentiment_df = pd.concat([jokes_df, answer_sentiment_all_df], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRMqfyRBe8-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "68d8101e-d4ff-40a4-becc-5b8b28801978"
      },
      "source": [
        "jokes_sentiment_df.head()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>question_answer</th>\n",
              "      <th>label</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What do you do if a bird shits on your car</td>\n",
              "      <td>Don't ask her out again.</td>\n",
              "      <td>What do you do if a bird shits on your car?  D...</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.985106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What should you do before criticizing Pac-Man</td>\n",
              "      <td>WAKA WAKA WAKA mile in his shoes</td>\n",
              "      <td>What should you do before criticizing Pac-Man?...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.932200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What's the difference between an illegal Mexic...</td>\n",
              "      <td>Nothing... they were both made to steal Ameri...</td>\n",
              "      <td>What's the difference between an illegal Mexic...</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.999485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What do you call a barbarian you can't see</td>\n",
              "      <td>an Invisigoth.</td>\n",
              "      <td>What do you call a barbarian you can't see?  a...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.772967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What did Arnold Schwarzenegger say at the abor...</td>\n",
              "      <td>Hasta last vista, baby.</td>\n",
              "      <td>What did Arnold Schwarzenegger say at the abor...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.994798</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  ...     score\n",
              "0         What do you do if a bird shits on your car  ...  0.985106\n",
              "1      What should you do before criticizing Pac-Man  ...  0.932200\n",
              "2  What's the difference between an illegal Mexic...  ...  0.999485\n",
              "3         What do you call a barbarian you can't see  ...  0.772967\n",
              "4  What did Arnold Schwarzenegger say at the abor...  ...  0.994798\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSMzJgZoe-zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#jokes_sentiment_df.to_csv('riddle_jokes_answer_sentiment.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9aGl472nJvW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "27abcf29-d280-4295-b587-687b8d16a673"
      },
      "source": [
        "ls sample_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;32manscombe.json\u001b[0m*                mnist_test.csv\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  \u001b[01;32mREADME.md\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3NPVTRDOfZtZ",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7d5d97a0-c078-4071-8ac6-7542c1988189",
        "id": "rpRjTD-hfZtc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#!gsutil cp riddle_jokes_answer_sentiment.csv gs://joke-generator-model1/"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://riddle_jokes_answer_sentiment.csv [Content-Type=text/csv]...\n",
            "-\n",
            "Operation completed over 1 objects/12.3 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq7aeRUKndNy",
        "colab_type": "text"
      },
      "source": [
        "## Convert riddle df to string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6_KPSPmfZcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def riddle_df_to_str(df, target_fp):\n",
        "    sentiment_tags = df.label.apply(lambda x: '<positive>' if x == 'POSITIVE' else '<negative>')\n",
        "    riddle_jokes_list = (\n",
        "        \"<soq> \" + sentiment_tags + \" \" + df.question + \" <eoq> \" + df.answer + \" <|endoftext|>\"\n",
        "    ).values.tolist()\n",
        "    riddle_jokes = \"\\n\".join(riddle_jokes_list)\n",
        "\n",
        "    with open(target_fp, \"w\") as f:\n",
        "        f.write(riddle_jokes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6_TLupFfZiG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f96ea509-8a8f-44b5-da35-88bd477e96c4"
      },
      "source": [
        "!gsutil cp gs://joke-generator-model1/riddle_jokes_answer_sentiment.csv riddle_jokes_answer_sentiment.csv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://joke-generator-model1/riddle_jokes_answer_sentiment.csv...\n",
            "- [1 files][ 12.3 MiB/ 12.3 MiB]                                                \n",
            "Operation completed over 1 objects/12.3 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXVlWl2Zntw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "jokes_sentiment_df = pd.read_csv('riddle_jokes_answer_sentiment.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcptT1k3m_tP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "76346e78-06aa-4697-bd42-cc9fde21d535"
      },
      "source": [
        "riddle_str = riddle_df_to_str(jokes_sentiment_df, 'riddle_jokes_answer_sentiment.txt')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ce51a4ac7a74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mriddle_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mriddle_df_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjokes_sentiment_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'riddle_jokes_answer_sentiment.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'riddle_df_to_str' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeO56FX1oWlI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "63735a57-93f1-4889-a1da-630cdba087a2"
      },
      "source": [
        "# Looks good\n",
        "!head -5 riddle_jokes_answer_sentiment.txt"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<soq> <negative> What do you do if a bird shits on your car <eoq>  Don't ask her out again. <|endoftext|>\n",
            "<soq> <positive> What should you do before criticizing Pac-Man <eoq>  WAKA WAKA WAKA mile in his shoes <|endoftext|>\n",
            "<soq> <negative> What's the difference between an illegal Mexican and an autonomous robot... <eoq>  Nothing... they were both made to steal American jobs. <|endoftext|>\n",
            "<soq> <positive> What do you call a barbarian you can't see <eoq>  an Invisigoth. <|endoftext|>\n",
            "<soq> <positive> What did Arnold Schwarzenegger say at the abortion clinic <eoq>  Hasta last vista, baby. <|endoftext|>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFGQQnYKoXg3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41bf7143-2ec4-4be4-9c5d-9dddcb9be808"
      },
      "source": [
        "!gsutil cp riddle_jokes_answer_sentiment.txt gs://joke-generator-model1/riddle_jokes_answer_sentiment_20200409.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CommandException: No URLs matched: riddle_jokes_answer_sentiment.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrHXIsT0oXjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrR_HcV974pd",
        "colab_type": "text"
      },
      "source": [
        "## Save tokenizer w/ new tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi5UHRsUygzy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d7e42daa-f000-4358-ad48-1fcee281703a"
      },
      "source": [
        "!gsutil cp gs://joke-generator-model1/riddle_jokes_answer_sentiment_20200409.txt riddle_jokes_answer_sentiment.txt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://joke-generator-model1/riddle_jokes_answer_sentiment_20200409.txt...\n",
            "- [1 files][  7.4 MiB/  7.4 MiB]                                                \n",
            "Operation completed over 1 objects/7.4 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXGk3kvG5y0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import GPT2Model, GPT2Config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "876uujUue_mQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer\n",
        "#from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfUei-WV2LUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir models\n",
        "!mkdir models/pretrained\n",
        "!mkdir models/finetuned"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46_vX3B02LZv",
        "colab_type": "code",
        "outputId": "21c14471-f4c0-4e7c-fad5-cec6e250be19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "66a8d6ad150047838c4f168d329d91b8",
            "8adabf6ff09a4fd1a4531cb727f9aa41",
            "8fea8ea771b84598883bfe56c9983568",
            "91f66713021c4da9bc48033cf4b2549e",
            "d4ea6a601ca049ef96577b02393d1997",
            "eb538b9d0bd74f7e8773c4261c2caccb",
            "bb7a10908c374f1c91174464551383fc",
            "e4ef910d7a254375b2f6836b6dfed220",
            "44268d8feb9043b9883d8d1a21222bdb",
            "bd659c2860a84c74a1f30d2e031058fb",
            "69dbb4d7420c46c98609428aa6c14009",
            "6111df32c13746629cb127c084cb288d",
            "78ff1dd0b09f4dafb28c5a610b3e3a50",
            "3d529758637c4d5b9d91db244e9251df",
            "4ecfb48304fe4f17b51427d63ae60971",
            "939a52efbd3a4bbf86a70dc43c99b968"
          ]
        }
      },
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "# Adding the sentiment tokens as additional tokens\n",
        "new_tokens = ['<soq>', '<eoq>', '<negative>', '<positive>']\n",
        "num_added_toks = tokenizer.add_tokens(new_tokens)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66a8d6ad150047838c4f168d329d91b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=1042301, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44268d8feb9043b9883d8d1a21222bdb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=456318, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fmn8DFtdmdB",
        "colab_type": "code",
        "outputId": "faa36b66-ba10-4b8c-c729-cf34e7ba3ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer._convert_token_to_id(\"<|endoftext|>\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzqX92toqT6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "843636db-dda4-4d6a-c461-839543f91d3b"
      },
      "source": [
        "#for token in new_tokens:\n",
        "#    print(tokenizer._convert_token_to_id(token))\n",
        "num_added_toks"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwBqW22r2Wgf",
        "colab_type": "code",
        "outputId": "ff3b9b26-217f-4136-870c-4290c3ada6e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "tokenizer.save_pretrained('./models/pretrained')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./models/pretrained/vocab.json',\n",
              " './models/pretrained/merges.txt',\n",
              " './models/pretrained/special_tokens_map.json',\n",
              " './models/pretrained/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ncu5OFG1q4Tr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b51a4a15-b880-4022-b34b-9aa1f7f4324f"
      },
      "source": [
        "# New tokens are stored in added_tokens.json\n",
        "cat ./models/pretrained/added_tokens.json"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"<soq>\": 50257, \"<eoq>\": 50258, \"<negative>\": 50259, \"<positive>\": 50260}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sKmQkmh25UZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "46e34f28-635a-4af5-e387-de38f44df92b"
      },
      "source": [
        "!head -5 ./riddle_jokes_answer_sentiment.txt"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<soq> <negative> What do you do if a bird shits on your car <eoq>  Don't ask her out again. <|endoftext|>\n",
            "<soq> <positive> What should you do before criticizing Pac-Man <eoq>  WAKA WAKA WAKA mile in his shoes <|endoftext|>\n",
            "<soq> <negative> What's the difference between an illegal Mexican and an autonomous robot... <eoq>  Nothing... they were both made to steal American jobs. <|endoftext|>\n",
            "<soq> <positive> What do you call a barbarian you can't see <eoq>  an Invisigoth. <|endoftext|>\n",
            "<soq> <positive> What did Arnold Schwarzenegger say at the abortion clinic <eoq>  Hasta last vista, baby. <|endoftext|>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrtBZpdy58VD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "with open('./models/pretrained/config.json', 'w') as f:\n",
        "    json.dump(GPT2Config().to_dict(), f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKk7-T4jbiyl",
        "colab_type": "text"
      },
      "source": [
        "## Finetune the GPT2 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM6XSIzF0glw",
        "colab_type": "code",
        "outputId": "0255b83b-ff79-40b8-d1c8-b1b38f986457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python transformers/examples/run_language_modeling.py\\\n",
        "    --overwrite_output_dir\\\n",
        "    --output_dir=./models/finetuned \\\n",
        "    --model_type=gpt2\\\n",
        "    --model_name_or_path=gpt2\\\n",
        "    --tokenizer_name ./models/pretrained \\\n",
        "    --do_train\\\n",
        "    --train_data_file=./riddle_jokes_answer_sentiment.txt \\\n",
        "    --per_gpu_train_batch_size 10 \\\n",
        "    --block_size 100 # Set this arbitrarily for now. But most jokes will be within this range. We don't want to weight super long jokes anyway.\\"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/09/2020 12:13:34 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "04/09/2020 12:13:34 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942\n",
            "04/09/2020 12:13:34 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"_num_labels\": 2,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "04/09/2020 12:13:34 - INFO - transformers.configuration_utils -   loading configuration file ./models/pretrained/config.json\n",
            "04/09/2020 12:13:34 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"_num_labels\": 2,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": null,\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "04/09/2020 12:13:34 - INFO - transformers.tokenization_utils -   Model name './models/pretrained' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming './models/pretrained' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "04/09/2020 12:13:34 - INFO - transformers.tokenization_utils -   loading file ./models/pretrained/vocab.json\n",
            "04/09/2020 12:13:34 - INFO - transformers.tokenization_utils -   loading file ./models/pretrained/merges.txt\n",
            "04/09/2020 12:13:34 - INFO - transformers.tokenization_utils -   loading file ./models/pretrained/added_tokens.json\n",
            "04/09/2020 12:13:34 - INFO - transformers.tokenization_utils -   loading file ./models/pretrained/special_tokens_map.json\n",
            "04/09/2020 12:13:35 - INFO - transformers.tokenization_utils -   loading file ./models/pretrained/tokenizer_config.json\n",
            "04/09/2020 12:13:35 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
            "Traceback (most recent call last):\n",
            "  File \"transformers/examples/run_language_modeling.py\", line 783, in <module>\n",
            "    main()\n",
            "  File \"transformers/examples/run_language_modeling.py\", line 710, in main\n",
            "    cache_dir=args.cache_dir,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py\", line 690, in from_pretrained\n",
            "    return model_class.from_pretrained(pretrained_model_name_or_path, *model_args, config=config, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\", line 516, in from_pretrained\n",
            "    state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 529, in load\n",
            "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 709, in _legacy_load\n",
            "    deserialized_objects[key]._set_from_file(f, offset, f_should_read_directly)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_CWfQgETs4",
        "colab_type": "text"
      },
      "source": [
        "## Test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u59dRezEbxX",
        "colab_type": "code",
        "outputId": "5aa7d581-c439-4c13-d240-e65a3babe460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l8AXGJoEVSB",
        "colab_type": "code",
        "outputId": "cbc9464e-d5a8-4d3e-ed58-1cfb5d0db916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python transformers/examples/run_generation.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=models/finetuned/ \\\n",
        "    --length=50 \\\n",
        "    --stop_token='<|endoftext|>' \\\n",
        "    --num_return_sequences 20"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/09/2020 12:15:53 - INFO - transformers.tokenization_utils -   Model name 'models/finetuned/' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'models/finetuned/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "04/09/2020 12:15:53 - INFO - transformers.tokenization_utils -   loading file models/finetuned/vocab.json\n",
            "04/09/2020 12:15:53 - INFO - transformers.tokenization_utils -   loading file models/finetuned/merges.txt\n",
            "04/09/2020 12:15:53 - INFO - transformers.tokenization_utils -   loading file models/finetuned/added_tokens.json\n",
            "04/09/2020 12:15:53 - INFO - transformers.tokenization_utils -   loading file models/finetuned/special_tokens_map.json\n",
            "04/09/2020 12:15:53 - INFO - transformers.tokenization_utils -   loading file models/finetuned/tokenizer_config.json\n",
            "04/09/2020 12:15:53 - INFO - transformers.configuration_utils -   loading configuration file models/finetuned/config.json\n",
            "04/09/2020 12:15:53 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"_num_labels\": 2,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50261\n",
            "}\n",
            "\n",
            "04/09/2020 12:15:53 - INFO - transformers.modeling_utils -   loading weights file models/finetuned/pytorch_model.bin\n",
            "04/09/2020 12:16:01 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=50, model_name_or_path='models/finetuned/', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=20, p=0.9, padding_text='', prompt='', repetition_penalty=1.0, seed=42, stop_token='<|endoftext|>', temperature=1.0, xlm_language='')\n",
            "Model prompt >>> <soq> <positive>\n",
            "04/09/2020 12:16:11 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "<soq> <positive>  What kind of vegetables do you get from your Facebook friends <eoq>   Fleshi\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "<soq> <positive>  How do you get cows to date <eoq>   In the cow eggs! (Photos)\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "<soq> <positive>  What do you get if you cross a bull and a cat <eoq>   A hollowness zoo\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "<soq> <positive>  How did the dog get to the bar <eoq>   He found his date.\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "<soq> <positive>  What do you call a lego rapid frog <eoq>   A bak-bake.\n",
            "=== GENERATED SEQUENCE 6 ===\n",
            "<soq> <positive>  What do you call a space dolphin <eoq>   A dangerous tuna.\n",
            "=== GENERATED SEQUENCE 7 ===\n",
            "<soq> <positive>  What does Santa say when he sees a baby in the oven <eoq>   Toots\n",
            "=== GENERATED SEQUENCE 8 ===\n",
            "<soq> <positive>  What did the Mexican joke have, because he was hungry.\n",
            "=== GENERATED SEQUENCE 9 ===\n",
            "<soq> <positive>  What did the ghost say to the dead boy <eoq>   \"Don't go looking for me! I don't see you!\"\n",
            "=== GENERATED SEQUENCE 10 ===\n",
            "<soq> <positive>  What do they do to die <eoq>   Be a lesbian.\n",
            "=== GENERATED SEQUENCE 11 ===\n",
            "<soq> <positive>  What do you call a magician with two-headed hydra <eoq>   A Beast.\n",
            "=== GENERATED SEQUENCE 12 ===\n",
            "<soq> <positive>  Why do my White Boy go with penguins <eoq>   She always smells good.\n",
            "=== GENERATED SEQUENCE 13 ===\n",
            "<soq> <positive>  Why did Jesus leave Greece <eoq>   Because there was no juice.\n",
            "=== GENERATED SEQUENCE 14 ===\n",
            "<soq> <positive>  How do you make a good mad scientist <eoq>   Homogenise the two diacritics in a single stone.\n",
            "=== GENERATED SEQUENCE 15 ===\n",
            "<soq> <positive>  What did one African American say to the other <eoq>   We both hate to fart\n",
            "=== GENERATED SEQUENCE 16 ===\n",
            "<soq> <positive>  How do you track a circus <eoq>   You feed it to the circus\n",
            "=== GENERATED SEQUENCE 17 ===\n",
            "<soq> <positive>  What do you get when you cross a Dutch woman and a Chinese nun <eoq>   Binomial times.\n",
            "=== GENERATED SEQUENCE 18 ===\n",
            "<soq> <positive>  What's the worst part about being stoned <eoq>   (get this from Reddit user iamhellshiny ) you cant remove your condoms from the house.\n",
            "=== GENERATED SEQUENCE 19 ===\n",
            "<soq> <positive>  What kind of sex will Sean Connery meet with a millionaire <eoq>   A pipe.\n",
            "=== GENERATED SEQUENCE 20 ===\n",
            "<soq> <positive>  What do you call the tall guy with two salivary glands <eoq>   Cowskin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFbmxiaVC6RW",
        "colab_type": "text"
      },
      "source": [
        "## Save results to gcs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUH9CChoC8uv",
        "colab_type": "code",
        "outputId": "ef76a062-67d4-4961-f9be-9e8396d4031a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd models/finetuned "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/finetuned\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI1ozA6UC_OA",
        "colab_type": "code",
        "outputId": "7c726c35-e511-446a-cb41-a7af1a7e513d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "added_tokens.json  \u001b[0m\u001b[01;34mcheckpoint-500\u001b[0m/  pytorch_model.bin        training_args.bin\n",
            "\u001b[01;34mcheckpoint-1000\u001b[0m/   config.json      special_tokens_map.json  vocab.json\n",
            "\u001b[01;34mcheckpoint-1500\u001b[0m/   merges.txt       tokenizer_config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3N_PfNyruuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir model2-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtFaNaRcruxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv added_tokens.json config.json merges.txt pytorch_model.bin special_tokens_map.json tokenizer_config.json training_args.bin vocab.json model2-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt1jh7QxDUQZ",
        "colab_type": "code",
        "outputId": "6ccc56ac-3ce4-43c2-a6ae-b48a050f2b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!zip -r model2-2.zip  model2-2"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model2-2/ (stored 0%)\n",
            "  adding: model2-2/vocab.json (deflated 63%)\n",
            "  adding: model2-2/training_args.bin (deflated 36%)\n",
            "  adding: model2-2/added_tokens.json (deflated 35%)\n",
            "  adding: model2-2/pytorch_model.bin (deflated 16%)\n",
            "  adding: model2-2/special_tokens_map.json (deflated 52%)\n",
            "  adding: model2-2/merges.txt (deflated 53%)\n",
            "  adding: model2-2/tokenizer_config.json (deflated 48%)\n",
            "  adding: model2-2/config.json (deflated 57%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eARMu0LzDiI0",
        "colab_type": "code",
        "outputId": "629c19ea-0f06-45fb-febc-9ce2fe4ca96e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "ls -l"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 452248\n",
            "drwxr-xr-x 2 root root      4096 Apr  9 12:03 \u001b[0m\u001b[01;34mcheckpoint-1000\u001b[0m/\n",
            "drwxr-xr-x 2 root root      4096 Apr  9 12:05 \u001b[01;34mcheckpoint-1500\u001b[0m/\n",
            "drwxr-xr-x 2 root root      4096 Apr  9 12:02 \u001b[01;34mcheckpoint-500\u001b[0m/\n",
            "drwxr-xr-x 2 root root      4096 Apr  9 12:17 \u001b[01;34mmodel2-2\u001b[0m/\n",
            "-rw-r--r-- 1 root root 463084808 Apr  9 12:18 model2-2.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BplpSyuSDteO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q9iaD0uD5O7",
        "colab_type": "code",
        "outputId": "ce020ee4-4f76-4ce2-f97a-85217f8225ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!gsutil cp model2-2.zip gs://joke-generator-model1/"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://model2-2.zip [Content-Type=application/zip]...\n",
            "/ [0 files][    0.0 B/441.6 MiB]                                                \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "|\n",
            "Operation completed over 1 objects/441.6 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQyrEVi4EIHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}